{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%run -i \"final_youtube.py\"\n",
    "#get collection of documents (minute of podcast) in a list\n",
    "file = \"2Lex/#101|Joscha_Bach|Artificial_Consciousness_and_the_Nature_of_Reality.txt\"\n",
    "with open(file, \"r\") as r:\n",
    "    topicnum = int(len(r.read().split(\" \"))/1500)\n",
    "podcast = podcast_to_collection(file, 500)\n",
    "#get normalized documents\n",
    "processed_pod = parallel_process(podcast)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#dictionary of words\n",
    "dictionary = gensim.corpora.Dictionary(processed_pod) #create dictionary for words\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.5, keep_n=100000) \n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_pod] #dict for how many times each word appears\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#bag of words model\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=topicnum, id2word=dictionary, passes=8, workers=60)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#tfidf model\n",
    "tfidf = models.TfidfModel(bow_corpus) \n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=topicnum, id2word=dictionary, passes=8, workers=30)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bow topics\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf topic\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[5]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[5]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_document = \"\"\n",
    "with open(file, \"r\") as r:\n",
    "    lines = r.readlines()\n",
    "    for line in lines:\n",
    "        unseen_document+=line.replace(\"\\n\", \" \")\n",
    "    unseen_document = \" \".join(unseen_document.split(\" \")[2600:3200])\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1])\n",
    "# for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "#     print(\"Score: {}\\t Topic: {}\\t Words: {}\".format(score, index, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_document = \"\"\n",
    "with open(file, \"r\") as r:\n",
    "    lines = r.readlines()\n",
    "    for line in lines:\n",
    "        unseen_document+=line.replace(\"\\n\", \" \")\n",
    "    unseen_document = \" \".join(unseen_document.split(\" \")[3200:3800])\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unseen_document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (3.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
