{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Æthelred\n",
      "married Æthelred\n",
      "Harthacnut\n",
      "Following Harthacnut\n",
      "Emma\n",
      "wanted Emma\n",
      "Æthelred\n",
      "but Æthelred\n",
      "Æthelred\n",
      ". Æthelred\n",
      "Cnut\n",
      "against Cnut\n",
      "Godwin\n",
      "married Godwin\n",
      "Godwin\n",
      "of Godwin\n",
      "saint\n",
      "conventional saint\n",
      "Peter\n",
      "St. Peter\n",
      "Peter\n",
      "St. Peter\n",
      "Cnut\n",
      "of Cnut\n",
      "Peter\n",
      "St. Peter\n",
      "Peter\n",
      "St. Peter\n",
      "John\n",
      "St. John\n",
      "John\n",
      "did John\n",
      "pope\n",
      "the pope\n",
      "Worcester\n",
      "first Worcester\n",
      "Wulfstan\n",
      ". Wulfstan\n",
      "Kean\n",
      "Henry Kean\n",
      "Peter\n",
      "St. Peter\n",
      "Cnut\n",
      "of Cnut\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "%run -i 'nlp_implementation.py'\n",
    "alltext = nlp(text_fix(open(\"text_files/all_fix.txt\").read()))\n",
    "quotes = nlp(text_fix(open(\"text_files/gonnadelete.txt\").read()))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp.txt\", \"w+\") as w:\n",
    "    for sent in alltext.sents:\n",
    "        w.write(str(sent.text+\"\\n\"))\n",
    "#     for tok in sent:\n",
    "#         if tok._.partquote==True:\n",
    "#             print(sent.text,\"\\n\")\n",
    "#             break\n",
    "#         print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "def get_quote\n",
    "\n",
    "city_getter = lambda span: any(city in span.text for city in (\"New York\", \"Paris\", \"Berlin\"))\n",
    "Span.set_extension(\"has_city\", getter=city_getter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "I\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp.txt\", \"w+\") as w:\n",
    "    for sent in alltext.sents:\n",
    "        w.write(str(\"*** \"+sent.text+\"\\n\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unimportant sentences\n",
    "with open(\"gonnadelete.txt\", \"w+\") as w:\n",
    "    for sent in alltext.sents:\n",
    "        if len(sent) <6:\n",
    "            w.write(str(sent)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alltext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/pod_agg/final_spacy_doc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_files/nounchunks2.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malltext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alltext' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"text_files/nounchunks2.txt\", \"w+\") as w:\n",
    "    for sent in alltext.sents:\n",
    "        w.write(sent.text)\n",
    "        w.write(\"\\n\")\n",
    "        for token in sent:\n",
    "            if token.pos_==\"NOUN\" or token.pos_==\"PROPN\":\n",
    "                w.write((str(token)+\" ****** \"))\n",
    "        w.write(\"\\n\")\n",
    "        for token in sent:\n",
    "            if token.pos_==\"VERB\":\n",
    "                w.write((str(token)+\" ****** \"))\n",
    "        w.write(\"\\n\\n\\n\")\n",
    "# find_noun(doc, \"plural\")\n",
    "# for i in range(len(quicktext)):\n",
    "#     print(quicktext[i].text, quicktext[i].pos_, quicktext[i].tag_, quicktext[i].dep_, quicktext[i].head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not know if I am going to be able to remember all of them, but you have Wessex, Essex, East Anglia, Mercia, Strathclyde, Northumbria, and then the Welsh Kingdoms. ***** I\n",
      "I feel like I am forgetting one ***** I\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    doc = nlp(contractions.fix(text))\n",
    "    spans = doc.sents\n",
    "    with open(\"iWords.txt\", \"w+\") as w:\n",
    "        for sent in doc.sents:\n",
    "            for word in sent:\n",
    "                if word.pos_ == \"PRON\":\n",
    "                    print(sent, \"*****\", word)\n",
    "                break\n",
    "\n",
    "clean_text(minitext)\n",
    "# clean_text(top_sentence(contractions.fix(open(\"all.txt\").read()), 100))\n",
    "# displacy.render(nlp(\"I do not know if I am going to be able to remember all of them, but you have Wessex, Essex, East Anglia, Mercia, Strathclyde, Northumbria, and then the Welsh Kingdoms\"), style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbsy [] dobj [('cola', 'soda')] \n",
      "verbsy [('order', 'want', 'give', 'make')] dobj [] \n",
      "verbsy [('order', 'want', 'give', 'make')] dobj [] \n",
      "orderCola\n"
     ]
    }
   ],
   "source": [
    "#intent from multiple sentences\n",
    "\n",
    "doc = nlp(\"I have finsihed my soda. I want another one.I want another one.\")\n",
    "verbList = [(\"order\", \"want\", \"give\", \"make\"), (\"show\", \"find\")]\n",
    "dobjList = [(\"pizza\", \"pie\", \"pizzaz\"), (\"cola\", \"soda\")]\n",
    "substitutes = [(\"one\", \"it\", \"same\", \"more\")] # things to replace\n",
    "intent = {'verb':\",'dobj':\"}\n",
    "\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        if token.dep_ == 'dobj':\n",
    "            verbSyns = [item for item in verbList if token.head.text in item]\n",
    "            dobjSyns = [item for item in dobjList if token.text in item]\n",
    "            substitute = [item for item in substitutes if token.text in item]\n",
    "            if (dobjSyns != [] or substitute !=[]) and verbSyns !=[]:\n",
    "                intent['verb'] = verbSyns[0][0]\n",
    "            if dobjSyns !=[]:\n",
    "                intent['dobj'] = dobjSyns[0][0]\n",
    "            print(\"verbsy\", verbSyns, \"dobj\", dobjSyns, \"\")\n",
    "intentStr = intent['verb'] + intent['dobj'].capitalize()\n",
    "print(intentStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I want to place an order for a pizza\") #want intent if main words are not transitive verb or direct object\n",
    "dobj, tverb = \"\", \"\"\n",
    "\n",
    "for token in doc: #find direct object and corressponding transitive verb\n",
    "    if token.dep_ == \"dobj\":\n",
    "        dobj = token\n",
    "        tverb = token.head\n",
    "intentVerb = \"\"\n",
    "verbList = [\"want\", \"like\", \"need\", \"order\"]\n",
    "if tverb.text in verbList:# if tverb is what we are looking for\n",
    "    intentVerb = tverb\n",
    "else:\n",
    "    if tverb.head.dep_ == \"ROOT\":#if not, then we look at root of sentence for real intent verb\n",
    "        intentVerb = tverb.head\n",
    "intentObj = \"\"\n",
    "objList = ['pizza', 'cola']\n",
    "if dobj.text in objList:\n",
    "    intentObj = dobj\n",
    "else: \n",
    "    for child in dobj.children:\n",
    "        if child.dep_ == 'prep':\n",
    "            intentObj = list(child.children)[0]\n",
    "            break\n",
    "        elif child.dep_ == 'compound':\n",
    "            intentObj = child\n",
    "            break\n",
    "print(intentVerb.text + intentObj.text.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "4.26 million\n",
      "The company earned revenue 4.26 million\n"
     ]
    }
   ],
   "source": [
    "print(\"test\") \n",
    "\n",
    "def extract_report(doc): \n",
    "    phrase = '' \n",
    "    for token in doc: \n",
    "#         print(token.text, token.pos_, spacy.explain(token.pos_), token.dep_, token.head)\n",
    "        if token.pos_ ==\"NUM\":\n",
    "#             print(token.text, token.head.text)\n",
    "            while True:\n",
    "                phrase += \" \"+token.text\n",
    "                token = token.head\n",
    "                if token not in list(token.head.lefts):\n",
    "                    phrase += \" \"+token.text\n",
    "                    break\n",
    "            \n",
    "            for i in token.subtree:\n",
    "                if i.dep_ == \"acl\":\n",
    "                    phrase +=\" \" + i.text\n",
    "                    break\n",
    "            break\n",
    "    phrase = phrase.strip()\n",
    "    print(phrase)\n",
    "#     print(doc[token.i].text)\n",
    "    while True:\n",
    "        token = doc[token.i].head\n",
    "\n",
    "        if token.pos_ != \"ADP\":\n",
    "            phrase = token.text +\" \"+ phrase\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            break\n",
    "    # print(phrase)\n",
    "    for tok in token.lefts:\n",
    "        if tok.dep_==\"nsubj\":\n",
    "    #         print([tok.text for tok in tok.lefts], tok.text)\n",
    "            phrase = \" \".join([tok.text for tok in tok.lefts]) + ' ' + tok.text + ' ' + phrase\n",
    "            break\n",
    "#     print(phrase) \n",
    "    return phrase\n",
    "doc = nlp(\"The company, whose profits reached a record high this year, largely attributed to changes in management, earned a total revenue of $4.26 million.\")\n",
    "\n",
    "phrase = extract_report(doc)\n",
    "print(phrase)\n",
    "\n",
    "# for i, token in enumerate(doc): \n",
    "#     print(token.text, token.pos_, spacy.explain(token.pos_), token.dep_, token.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/koko/system/anaconda/envs/python38/lib/python3.8/runpy.py:193: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  return _run_code(code, main_globals, None,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6d389d8a4cbb4376814d648355b3e3f6-0\" class=\"displacy\" width=\"4250\" height=\"662.0\" direction=\"ltr\" style=\"max-width: none; height: 662.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">company,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">whose</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">profits</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">reached</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">record</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">high</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">this</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">year,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">largely</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">attributed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">changes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">management,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">earned</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">total</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">revenue</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">4.26</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">million.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-0\" stroke-width=\"2px\" d=\"M70,527.0 C70,439.5 200.0,439.5 200.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,529.0 L62,517.0 78,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-1\" stroke-width=\"2px\" d=\"M245,527.0 C245,2.0 2850.0,2.0 2850.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,529.0 L237,517.0 253,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-2\" stroke-width=\"2px\" d=\"M420,527.0 C420,439.5 550.0,439.5 550.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,529.0 L412,517.0 428,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-3\" stroke-width=\"2px\" d=\"M595,527.0 C595,439.5 725.0,439.5 725.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,529.0 L587,517.0 603,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-4\" stroke-width=\"2px\" d=\"M245,527.0 C245,264.5 735.0,264.5 735.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M735.0,529.0 L743.0,517.0 727.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-5\" stroke-width=\"2px\" d=\"M945,527.0 C945,439.5 1075.0,439.5 1075.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,529.0 L937,517.0 953,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-6\" stroke-width=\"2px\" d=\"M770,527.0 C770,352.0 1080.0,352.0 1080.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1080.0,529.0 L1088.0,517.0 1072.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-7\" stroke-width=\"2px\" d=\"M1120,527.0 C1120,439.5 1250.0,439.5 1250.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1250.0,529.0 L1258.0,517.0 1242.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-8\" stroke-width=\"2px\" d=\"M1470,527.0 C1470,439.5 1600.0,439.5 1600.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,529.0 L1462,517.0 1478,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-9\" stroke-width=\"2px\" d=\"M770,527.0 C770,177.0 1615.0,177.0 1615.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1615.0,529.0 L1623.0,517.0 1607.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-10\" stroke-width=\"2px\" d=\"M1820,527.0 C1820,439.5 1950.0,439.5 1950.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,529.0 L1812,517.0 1828,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-11\" stroke-width=\"2px\" d=\"M245,527.0 C245,89.5 1970.0,89.5 1970.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1970.0,529.0 L1978.0,517.0 1962.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-12\" stroke-width=\"2px\" d=\"M1995,527.0 C1995,439.5 2125.0,439.5 2125.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2125.0,529.0 L2133.0,517.0 2117.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-13\" stroke-width=\"2px\" d=\"M2170,527.0 C2170,439.5 2300.0,439.5 2300.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2300.0,529.0 L2308.0,517.0 2292.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-14\" stroke-width=\"2px\" d=\"M2345,527.0 C2345,439.5 2475.0,439.5 2475.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2475.0,529.0 L2483.0,517.0 2467.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-15\" stroke-width=\"2px\" d=\"M2520,527.0 C2520,439.5 2650.0,439.5 2650.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2650.0,529.0 L2658.0,517.0 2642.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-16\" stroke-width=\"2px\" d=\"M3045,527.0 C3045,352.0 3355.0,352.0 3355.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3045,529.0 L3037,517.0 3053,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-17\" stroke-width=\"2px\" d=\"M3220,527.0 C3220,439.5 3350.0,439.5 3350.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3220,529.0 L3212,517.0 3228,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-18\" stroke-width=\"2px\" d=\"M2870,527.0 C2870,264.5 3360.0,264.5 3360.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3360.0,529.0 L3368.0,517.0 3352.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-19\" stroke-width=\"2px\" d=\"M3395,527.0 C3395,439.5 3525.0,439.5 3525.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3525.0,529.0 L3533.0,517.0 3517.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-20\" stroke-width=\"2px\" d=\"M3745,527.0 C3745,352.0 4055.0,352.0 4055.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3745,529.0 L3737,517.0 3753,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-21\" stroke-width=\"2px\" d=\"M3920,527.0 C3920,439.5 4050.0,439.5 4050.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3920,529.0 L3912,517.0 3928,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d389d8a4cbb4376814d648355b3e3f6-0-22\" stroke-width=\"2px\" d=\"M3570,527.0 C3570,264.5 4060.0,264.5 4060.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d389d8a4cbb4376814d648355b3e3f6-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4060.0,529.0 L4068.0,517.0 4052.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displacy.serve(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it seems the user wants a ticket to  failure to determine\n"
     ]
    }
   ],
   "source": [
    "def det_destination(doc):\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.ent_type!=0 and token.ent_type ==\"GPE\":\n",
    "            while True: #keep iterating back from gpe to either word \"to\" or the root\n",
    "                token = token.head\n",
    "                if token.text == \"to\":\n",
    "                    return doc[i].text\n",
    "                if token.head == token: #if we reach root and no to is found\n",
    "                    return \"failure to determine\"\n",
    "    return \"failure to determine\"\n",
    "\n",
    "\n",
    "\n",
    "dot = nlp(\"I am going to the conference in Berlin\")\n",
    "print(\"It seems the user wants a ticket to \", det_destination(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pronoun\n",
      "I can recognize the symbols too.\n"
     ]
    }
   ],
   "source": [
    "def dep_pattern(doc): #iterate through tokens to find subject + auxiliary + Root + object pattern\n",
    "    for i in range(len(doc)):\n",
    "        if doc[i].dep_ == 'nsubj' and doc[i+1].dep_ == \"aux\" and doc[i+2].dep_ == \"ROOT\":\n",
    "            for tok in doc[i+2].children:\n",
    "                if tok.dep_== \"dobj\":\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def pos_pattern(doc): #iterate through tokens,check if dep_ pattern subject and object are both personal pronouns\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'nsubj' and token.tag_ != 'PRP': #prp is personal pronoun\n",
    "            return False\n",
    "        if token.dep_ == 'aux' and token.tag_ != 'MD':\n",
    "            return False\n",
    "        if token.dep_ == 'ROOT' and token.tag_ != 'VB':\n",
    "            return False\n",
    "        if token.dep_ == 'dobj' and token.tag_ != 'PRP':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def pron_pattern(doc):\n",
    "    plural = [\"we\", \"us\", \"they\", \"them\"]\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"dobj\" and token.tag_ == \"PRP\":\n",
    "            if token.text in plural:\n",
    "                print(spacy.explain(token.pos_))\n",
    "                return 'plural'\n",
    "            else:\n",
    "                return 'regular'\n",
    "            \n",
    "    return \"not found\"\n",
    "def find_noun(sents, num):\n",
    "    if num ==\"plural\":\n",
    "        taglist = [\"NNS\", \"NNPS\"]\n",
    "    if num ==\"singular\":\n",
    "        taglist = [\"NN\", \"NNP\"]\n",
    "    for sent in reversed(sents):\n",
    "        for token in sent:\n",
    "            if token.tag_ in taglist:\n",
    "                current_noun = token.text\n",
    "                for w in token.children:\n",
    "                    if w.dep_ == \"det\":\n",
    "                        current_noun = w.text + \" \" + current_noun\n",
    "                return current_noun\n",
    "    return \"noun not found\"\n",
    "\n",
    "def gen_utterance(doc, noun):\n",
    "    sent = ''\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.dep_ == 'dobj' and token.tag_ == 'PRP':\n",
    "            sent = doc[:i].text+' '+noun.lower()+' '+doc[i+1:len(doc)-2].text + 'too.'\n",
    "            return sent\n",
    "        \n",
    "    return \"failed to generate utterance\"\n",
    "\n",
    "\n",
    "\n",
    "doc = nlp(\"The symbols are clearly distinguishable. I can recognize them promptly.\")\n",
    "# displacy.serve(doc, style=\"dep\")\n",
    "# for tok in doc:\n",
    "#     print(tok.text, tok.tag_,spacy.explain(tok.tag_), \"****\", tok.head, tok.dep_, spacy.explain(tok.dep_))\n",
    "sents = list(doc.sents)\n",
    "response = ''\n",
    "noun = ''\n",
    "for i, sent in enumerate(sents):\n",
    "    if dep_pattern(sent) and pos_pattern(sent):\n",
    "        noun = find_noun(sents[:i], pron_pattern(sent))\n",
    "        if noun != \"noun not found\":\n",
    "            response = gen_utterance(sents[i], noun)\n",
    "            break\n",
    "print(response)          \n",
    "\n",
    "\n",
    "\n",
    "# if dep_pattern(doc) and pos_pattern(doc):\n",
    "#     print(\"we gucci and\", pron_pattern(doc))\n",
    "# else:\n",
    "#     print(\"fuck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.21712280212037027, 1: 0.5007358701854312, 2: 0.3960727373866738}\n"
     ]
    }
   ],
   "source": [
    "token = nlp(\"fruits\")[0]\n",
    "doc = nlp(\"I want to buy this beautiful book at the end of the week. Sales of citrus have increased over the last year. How much do you know about this type of tree?\")\n",
    "similarity = {}\n",
    "for i, sent in enumerate(doc.sents):\n",
    "    noun_span_list = [sent[j].text for j in range(len(sent)) if sent[j].pos_ == 'NOUN']\n",
    "    noun_span_str = \" \".join(noun_span_list)\n",
    "    noun_span_doc = nlp(noun_span_str)\n",
    "    similarity.update({i:token.similarity(noun_span_doc)})\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Google', 'Search', 'Google', 'each', 'day']\n",
      "['Microsoft', 'Windows', 'Microsoft']\n",
      "['Titicaca', 'mountain', 'lake', 'Andes']\n",
      "doc1 is similar to doc2: 0.4816575733630022\n",
      "doc1 is similar to doc3: 0.15043614277821551\n",
      "doc2 is similar to doc3: 0.09657172685749982\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(u'Google Search, often referred to as simply Google, is the mostused search engine nowadays. It handles a huge number of searches each day.') \n",
    "#second sample text\n",
    "doc2 = nlp(u'Microsoft Windows is a family of proprietary operating systems developed and sold by Microsoft. The company also produces a wide range of other software for desktops and servers.') \n",
    "#third sample text\n",
    "doc3 = nlp(u\"Titicaca is a large, deep, mountain lake in the Andes. It is known as the highest navigable lake in the world.\")\n",
    "docs = [doc1, doc2, doc3]\n",
    "spans = {}\n",
    "for j, doc in enumerate(docs):\n",
    "    ner_span = [doc[i].text for i in range(len(doc)) if doc[i].ent_type != 0]\n",
    "#     ner_span = [(e.text, e.label_, e.type_) for e in doc.ents]\n",
    "    print(ner_span)\n",
    "    ner_span = \" \".join(ner_span)\n",
    "    ner_span = nlp(ner_span)\n",
    "    spans.update({j:ner_span})\n",
    "print('doc1 is similar to doc2:',spans[0].similarity(spans[1]))\n",
    "print('doc1 is similar to doc3:',spans[0].similarity(spans[2]))\n",
    "print('doc2 is similar to doc3:',spans[1].similarity(spans[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "england is similar to anglo: 0.5597197197306779\n",
      "india is similar to pakistan: 0.7873384940601342\n",
      "england is similar to pakistan: 0.6475954927068458\n"
     ]
    }
   ],
   "source": [
    "print('england is similar to anglo:',nlp(\"england\").similarity(nlp(\"india\")))\n",
    "print('india is similar to pakistan:',nlp(\"india\").similarity(nlp(\"pakistan\")))\n",
    "print('england is similar to pakistan:',nlp(\"england\").similarity(nlp(\"america\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON PRP pronoun, personal **** promise nsubj nominal subject\n",
      "can VERB MD verb, modal auxiliary **** promise aux auxiliary\n",
      "surely ADV RB adverb **** promise advmod adverbial modifier\n",
      "promise VERB VB verb, base form **** promise ROOT None\n",
      "it PRON PRP pronoun, personal **** is nsubj nominal subject\n",
      "is AUX VBZ verb, 3rd person singular present **** promise ccomp clausal complement\n",
      "worth ADJ JJ adjective **** is acomp adjectival complement\n",
      "your DET PRP$ pronoun, possessive **** time poss possession modifier\n",
      "time NOUN NN noun, singular or mass **** worth npadvmod noun phrase as adverbial modifier\n",
      ". PUNCT . punctuation mark, sentence closer **** promise punct punctuation\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I can surely promise it is worth your time.\")\n",
    "for tok in doc:\n",
    "    print(tok.text, tok.pos_,  tok.tag_,spacy.explain(tok.tag_), \"****\", tok.head, tok.dep_, spacy.explain(tok.dep_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I surely promise it is worth your time.\n"
     ]
    }
   ],
   "source": [
    "sent = ''\n",
    "for i, token in enumerate(doc):\n",
    "    if token.tag_ == \"PRP\" and doc[i+1].tag_ == \"MD\":\n",
    "        sent.append(doc[i+1].text.capitalize() + ' '+ doc[i].text +' '+ doc[i+2:].text)\n",
    "\n",
    "doc = nlp(sent)\n",
    "for i, token in (doc):\n",
    "    if token.tag_ == \"PRP\" and \n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chunk(doc):\n",
    "    chunk = \"\"\n",
    "    for i, tok in enumerate(doc):\n",
    "        if tok.dep_ == \"dobj\":\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRP pronoun, personal **** nsubj nominal subject\n",
      "want VBP verb, non-3rd person singular present **** ROOT None\n",
      "to TO infinitival \"to\" **** aux auxiliary\n",
      "order VB verb, base form **** xcomp open clausal complement\n",
      "a DT determiner **** det determiner\n",
      "vetgetarian JJ adjective **** amod adjectival modifier\n",
      "pizza NN noun, singular or mass **** dobj direct object\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I want to order a vetgetarian pizza\")\n",
    "for tok in doc:\n",
    "    print(tok.text, tok.tag_,spacy.explain(tok.tag_), \"****\", tok.dep_, spacy.explain(tok.dep_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we you nsubj\n",
      "must must aux\n",
      "overtake specify ROOT\n",
      "them it dobj\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"we must overtake them\")\n",
    "doc2 = nlp(\"you must specify it\")\n",
    "\n",
    "for i in range(0, len(doc1)):\n",
    "    if doc1[i].dep_ == doc2[i].dep_:\n",
    "        print(doc1[i].text, doc2[i].text, doc1[i].dep_,)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span:  We can overtake\n",
      "pos are 0 3\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"DEP\": \"nsubj\"}, {\"DEP\": \"aux\"}, {\"DEP\":\"ROOT\"}]\n",
    "matcher.add(\"nsubjauxroot\", None, pattern)\n",
    "doc = nlp(\"We can overtake them\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(\"Span: \", span.text)\n",
    "    print(\"pos are\", start ,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(sent):\n",
    "    ent1, ent2 = \"\", \"\"\n",
    "    prv_tok_dep, prv_tok_text = \"\",\"\"\n",
    "    prefix, modifier = \"\", \"\"\n",
    "    \n",
    "    for tok in nlp(sent):\n",
    "        if tok.dep_ != \"punct\":\n",
    "            print(\"\\nprevious tok dep:\", prv_tok_dep)\n",
    "            print(\"prev tok text: \", prv_tok_text)\n",
    "            print(\"pref:\", prefix)\n",
    "            print(\"modi:\", modifier)\n",
    "            \n",
    "            print(tok, \"...\", tok.dep_)\n",
    "            \n",
    "            if tok.dep_ == \"compound\" or tok.dep_.endswith(\"mod\") == True:\n",
    "                prefix = tok.text\n",
    "                if prv_tok_dep == \"compound\":\n",
    "                    prefix = prv_tok_text + \" \"+ tok.text\n",
    "            if tok.dep_.endswith(\"mod\") == True:\n",
    "                modifier = tok.text\n",
    "                if prv_tok_dep == \"compound\":\n",
    "                    modifier = prv_tok_text + \" \"+ tok.text\n",
    "            if \"subj\" in tok.dep_:\n",
    "                ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
    "                prefix = \"\"\n",
    "                modifier = \"\"\n",
    "                prv_tok_dep = \"\"\n",
    "                prv_tok_text = \"\" \n",
    "            if \"obj\" in tok.dep_:\n",
    "                ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
    "                print(\"fuck\", modifier, \"fuck\", prefix, \"fuck\", tok.text)\n",
    "#             else: \n",
    "#                 prv_tok_dep = \"\"\n",
    "#                 prv_tok_text = \"\" \n",
    "            \n",
    "        prv_tok_dep = tok.dep_\n",
    "        prv_tok_text = tok.text\n",
    "        print(\"\\nprevious tok dep:\", prv_tok_dep)\n",
    "        print(\"prev tok text: \", prv_tok_text)\n",
    "        print(\"pref:\", prefix)\n",
    "        print(\"modi:\", modifier)\n",
    "        print(\"\\n\\nentities:\", ent1, \"**** \",ent2)\n",
    "        print(\"****\")\n",
    "                    \n",
    "    \n",
    "    print(\"\\n\\nentities:\", ent1, \"**** \",ent2)\n",
    "    print(\"previous token stuff:\", prv_tok_dep, prv_tok_text)\n",
    "    print(\"pref:\", prefix)\n",
    "    print(\"modi:\", modifier)\n",
    "\n",
    "# get_entities(candidate_sentences[0].text)\n",
    "get_entities(\"the real estate drawdown process is governed by real estate standard d823\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Mary is playing a very old violin. She is very good at it.\"\"\"\n",
    "facts = nlp(text)\n",
    "facts._.coref_resolved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (3.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
